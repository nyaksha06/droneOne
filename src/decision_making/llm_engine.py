import asyncio
import logging
import sys
import requests
import json

logger = logging.getLogger(__name__)

class LLMDecisionEngine:
    """
    Communicates with the Ollama LLM to get drone action recommendations
    based on the current drone state and mission objectives.
    """

    def __init__(self, ollama_api_url: str, ollama_model_name: str):
        self.ollama_api_url = ollama_api_url
        self.ollama_model_name = ollama_model_name
        self.headers = {"Content-Type": "application/json"}
        logger.info(f"LLMDecisionEngine initialized for model '{ollama_model_name}' at {ollama_api_url}")

    async def get_action_from_llm(self, prompt_text: str) -> dict:
        """
        Sends the prompt to the Ollama LLM and parses the response into a structured action.
        This method is asynchronous to fit into our event loop, even if requests.post is blocking.
        (For true async HTTP, you'd use aiohttp or httpx with asyncio.)

        :param prompt_text: The detailed context prompt generated by DroneState.
        :return: A dictionary representing the recommended drone action, or an empty dict on failure.
                 Example: {"action": "goto_location", "latitude": X, "longitude": Y, "altitude": Z}
                          {"action": "land"}
                          {"action": "do_nothing"}
        """
        logger.info("Requesting action from LLM...")
        combined_prompt = (
            "You are a highly precise drone control AI assistant. "
            "Your ONLY task is to output a single JSON object representing a drone command. "
            "You MUST NOT include any conversational text, explanations, or extraneous characters "
            "outside of the JSON object itself. Adhere strictly to the provided JSON schema.\n\n"
            
            f"{prompt_text}\n\n"
            
            f"Based on this, respond ONLY with a JSON object that specifies the optimal drone action "
            f"and any necessary parameters. The action must be one of: 'takeoff', 'land', 'goto_location', 'do_nothing'.\n"
            f"The JSON object should conform to the following schema:\n"
            f"```json\n"
            f"{{\n"
            f'  "action": "takeoff" | "land" | "goto_location" | "do_nothing",\n'
            f'  "parameters": {{\n'
            f'    "altitude_m"?: float,      // Required for "takeoff", "goto_location" (e.g., 10.0)\n'
            f'    "latitude_deg"?: float,    // Required for "goto_location" (e.g., 47.3976)\n'
            f'    "longitude_deg"?: float    // Required for "goto_location" (e.g., 8.5456)\n'
            f'  }},\n'
            f'  "reason"?: string           // Optional human-readable reason for the action\n'
            f"}}\n"
            f"```\n"
            f"Ensure the JSON is well-formed and strictly follows this schema. Only output the JSON."
        )

        payload = {
            "model": self.ollama_model_name,
            "prompt": combined_prompt,
            "stream": False 
        }

        try:
           
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None, # Use default thread pool executor
                lambda: requests.post(self.ollama_api_url, headers=self.headers, data=json.dumps(payload), timeout=30)
            )
            
            response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)
            result = response.json()

            # Ollama's /api/generate usually returns a 'response' field with the generated text
            llm_raw_response_text = result.get("response", "").strip()
            logger.info(f"LLM Raw Response: {llm_raw_response_text}")

            
            action = self._parse_llm_response(llm_raw_response_text)
            
            if not action:
                logger.warning("LLM response could not be parsed into a valid action. Defaulting to 'do_nothing'.")
                return {"action": "do_nothing", "reason": "parsing_failed"}

            logger.info(f"LLM Recommended Action: {action}")
            return action

        except requests.exceptions.RequestException as e:
            logger.error(f"Error communicating with Ollama API: {e}")
            return {"action": "do_nothing", "reason": f"ollama_api_error: {e}"}
        except json.JSONDecodeError as e:
            logger.error(f"Error decoding LLM response JSON: {e}. Response text: {response.text}")
            return {"action": "do_nothing", "reason": f"json_decode_error: {e}"}
        except Exception as e:
            logger.error(f"An unexpected error occurred in get_action_from_llm: {e}")
            return {"action": "do_nothing", "reason": f"unexpected_error: {e}"}

    def _parse_llm_response(self, response_text: str) -> dict:
        """
        Parses the raw text response from the LLM, assuming it is a strict JSON string.
        This function will extract the JSON from a markdown block if present,
        or attempt to parse the entire response as JSON.
        """
        try:
            # Attempt to extract JSON from a markdown code block (common for LLMs)
            if response_text.startswith("```json") and response_text.endswith("```"):
                json_str = response_text.strip("```json").strip("```").strip()
            elif response_text.startswith("```") and response_text.endswith("```"): # Generic code block
                json_str = response_text.strip("```").strip()
            else:
                json_str = response_text # Assume it's directly JSON

            parsed_json = json.loads(json_str)

            # Basic validation of the parsed JSON
            if not isinstance(parsed_json, dict):
                logger.warning("LLM response is not a JSON object.")
                return {}
            if "action" not in parsed_json or not isinstance(parsed_json["action"], str):
                logger.warning("JSON response missing 'action' key or it's not a string.")
                return {}
            
            # Further validate action types and parameters
            valid_actions = ["takeoff", "land", "goto_location", "do_nothing"]
            if parsed_json["action"] not in valid_actions:
                logger.warning(f"Invalid action '{parsed_json['action']}' returned by LLM.")
                return {}

            if parsed_json["action"] == "takeoff" and ("parameters" not in parsed_json or "altitude_m" not in parsed_json["parameters"]):
                logger.warning("Takeoff action missing 'altitude_m' parameter. Providing default.")
                parsed_json.setdefault("parameters", {})["altitude_m"] = 2.5 # Default altitude
            
            if parsed_json["action"] == "goto_location":
                params = parsed_json.get("parameters", {})
                if not all(k in params for k in ["latitude_deg", "longitude_deg", "altitude_m"]):
                    logger.warning("Goto action missing required coordinates/altitude. Returning 'do_nothing'.")
                    return {}
                # Ensure types are correct
                try:
                    params["latitude_deg"] = float(params["latitude_deg"])
                    params["longitude_deg"] = float(params["longitude_deg"])
                    params["altitude_m"] = float(params["altitude_m"])
                except ValueError:
                    logger.warning("Goto parameters are not numbers. Returning 'do_nothing'.")
                    return {}

            return parsed_json

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse LLM response as JSON: {e}. Response: '{response_text}'")
            return {}
        except Exception as e:
            logger.error(f"An unexpected error occurred during LLM response parsing: {e}. Response: '{response_text}'")
            return {}

